---
title: Markov链学习记录
date: 2023-11-14 18:08 +0800
categories: [数学]
tags: [随机过程]     # TAG names should always be lowercase
---


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>


## Markov链的一步转移概率
\\[
P \lbrace X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, ... , X_1 = i_1, X_0 = i_0 \rbrace = P_{ij}
\\]  
通俗来讲，公式可方便理解为\\(P(将来|现在和过去) = P(将来|现在)\\)，即过去的状态\\(X_0, ..., X_{n-1}\\)和现在的状态\\(X_{n}\\)给定的情况下，任意未来状态\\(X_{n+1}\\)只依赖于现在的状态，这点性质可称为马尔可夫性,可引申为事件的将来和过去互相独立。

其中,  
\\[
P_{ij} \geq 0, \qquad  i,j \geq 0; \qquad \sum_{j=0}^{n}P_{ij}=1, \qquad i=0,1,...
\\]  
以\\(P\\)记为转移概率\\(P_{ij}\\)的矩阵，  
\\[
P=
\begin{Vmatrix}
P_{00} & P_{01} & P_{02} & ... \\
P_{10} & P_{11} & P_{12} & ... \\
P_{20} & P_{21} & P_{22} & ... \\
P_{30} & P_{31} & P_{32} & ... \\
\end{Vmatrix}
\\]
(由于MathJax的BUG，矩阵不能正常显示，请见谅\~)  
其中列表示到达的状态，行表示出发的状态，可重复演算推出\\(P\\)矩阵。  
## 首达概率、有限步到达概率与到达概率
\\[
f_{ij}(n):表示从i状态的进行n步后到达状态j的首次到达概率 
\\]
\\[
f_{ij}:从i状态转移到j状态不限定步数的首达概率
\\]
\\[
p_{ij}(n):从i状态转移到j状态进行n步后到达的概率
\\]
大小关系：\\(p_{ij}(n)\\)>\\(f_{ij}\\)>\\(f_{ij}(n)\\)
## 常返状态、瞬过状态
\\[
瞬过状态：f_{ii}<1
\\]
\\[
常返状态方程：
f_{ii} = 1 = \sum_{n=1}^{∞}f_{ii}(n)
\\]
在常返状态中，步数\\[E(n)=\sum_{n=1}^{∞}nf_{ii}(n)=μ_{i}\\]
\\[
当μ_{i}<+∞时，称i为正常返,
当μ_{i}=+∞时，称i为零常返     
\\]
$$
      1111
$$
 